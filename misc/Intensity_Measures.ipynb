{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797ecb78-07c7-46a0-8b92-4dbd4e5b7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from models.functions.data_loader import GeologyTracesDataset\n",
    "from models.functions.fno_model import FNO_3D\n",
    "from models.functions.uno_model import UNO_3D\n",
    "from models.functions.gfno_model import GFNO_3D\n",
    "from models.functions.ffno_model import FFNO_3D\n",
    "from models.functions.intensity_measures import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58914dfd-b5cc-4257-a07b-b4cef6e4eb99",
   "metadata": {},
   "source": [
    "This notebook load each trained model and plot the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef9728c-306f-4a01-bcd1-98b609b26947",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_in = 32 # Number of spatial points in inputs (dimensions x and y)\n",
    "S_in_z = 32 # Number of vertical points in inputs (dimension z)\n",
    "S_out = 32 # Number of spatial points in outputs (dimensions x and y)\n",
    "T_out = 320 # Number of timesteps\n",
    "dt = 0.02 # Time step in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0cf7eb-a610-45a9-90fb-28ed6dbb3a58",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f534c4ea-714a-4ae0-9e13-dc3f8187b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nval = 5 # Number of validation samples\n",
    "val_data = GeologyTracesDataset('./models/inputs/', ['inputs3D_S32_Z32_T320_fmax5_val'], \n",
    "                                S_in=S_in, S_in_z=S_in_z, S_out=S_out, T_out=T_out,\n",
    "                                transform_a='normal', N=Nval)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a211aec-9b41-4e24-aa12-29be1f89980e",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ef2b9-57dc-4dcd-957d-14392fd5934a",
   "metadata": {},
   "source": [
    "You should load only one model by running its corresponding cell, and then plot its predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb834c1-ac69-4f87-986c-f9e893499480",
   "metadata": {},
   "source": [
    "### FNO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878e2297-f124-4b93-bbe4-e19c04c05821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dv = 16 # Number of channels after the uplift\n",
    "in_width = 6 # Number of channels after the grid concatenation\n",
    "list_dv = [16, 16, 16, 16] # Number of channels after each block\n",
    "list_D1 = [32, 32, 32, 32] # Dimensions along the 1st dimension after each block\n",
    "list_D2 = [32, 32, 32, 32] # Dimensions along the 2nd dimension after each block\n",
    "list_D3 = [64, 128, 256, 320] # Dimensions along the 3rd dimension after each block\n",
    "list_M1 = [16, 16, 16, 16] # Number of modes along the 1st dimension after each block\n",
    "list_M2 = [16, 16, 16, 16] # Number of modes along the 2nd dimension after each block\n",
    "list_M3 = [16, 32, 32, 32] # Number of modes along the 3rd dimension after each block\n",
    "model_name = 'FNO'\n",
    "\n",
    "# build the model\n",
    "model = FNO_3D(in_width, dv, S_in, list_dv, list_D1, list_D2, list_D3, list_M1, list_M2, list_M3, padding=0)\n",
    "\n",
    "# load the weights from the trained model\n",
    "epochs = 158\n",
    "name_config = f'FNO3D-dv{dv}-S{S_in}-T{T_out}-learningrate0p0006-L1loss1p0-L2loss0p0-Ntrain27000-batchsize16'\n",
    "model.load_state_dict(torch.load(f'./models/logs/models/bestmodel-{name_config}-epochs{epochs}.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc975c51-e755-4db4-b0d5-6cefc5d2ae43",
   "metadata": {},
   "source": [
    "### UNO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374c7533-2834-47fd-9735-0401d5677ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dv = 16 # Number of channels after the uplift\n",
    "in_width = 6 # Number of channels after the grid concatenation\n",
    "list_dv = [16, 16, 16, 16, 16, 16, 16, 16] # Number of channels after each block\n",
    "list_D1 = [24, 18, 13, 8, 13, 18, 24, 32] # Dimensions along the 1st dimension after each block\n",
    "list_D2 = [24, 18, 13, 8, 13, 18, 24, 32] # Dimensions along the 2nd dimension after each block\n",
    "list_D3 = [24, 18, 13, 8, 17, 34, 64, 320] # Dimensions along the 3rd dimension after each block\n",
    "list_M1 = [12, 9, 6, 4, 4, 6, 9, 12, 12] # Number of modes along the 1st dimension after each block\n",
    "list_M2 = [12, 9, 6, 4, 4, 6, 9, 12, 12] # Number of modes along the 2nd dimension after each block\n",
    "list_M3 = [12, 9, 7, 5, 5, 9, 17, 20, 20] # Number of modes along the 3rd dimension after each block\n",
    "model_name = 'U-NO'\n",
    "\n",
    "# build the model\n",
    "model = UNO_3D(in_width, dv, S_in, list_dv, list_D1, list_D2, list_D3, list_M1, list_M2, list_M3, padding=0)\n",
    "\n",
    "# load the weights from the trained model\n",
    "epochs = 200\n",
    "name_config = f'UNO3D-dv{dv}-S{S_in}-T{T_out}-learningrate0p0006-L1loss1p0-L2loss0p0-Ntrain27000-batchsize16'\n",
    "model.load_state_dict(torch.load(f'./models/logs/models/bestmodel-{name_config}-epochs{epochs}.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e2766-966c-48fb-8f1c-5676697f550c",
   "metadata": {},
   "source": [
    "### G-FNO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b0cf8b-f5e3-43aa-8eca-bca3d3b5b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dv = 11 # Number of channels after the uplift\n",
    "num_channels = 1 # Number of channels in inputs\n",
    "list_dv = [16, 16, 16, 16] # Number of channels after each block\n",
    "list_D = [32, 32, 32, 32] # Dimensions along the 1st and 2nd dimension after each block\n",
    "list_D3 = [64, 128, 256, 320] # Dimensions along the 3rd dimension after each block\n",
    "list_M = [8, 8, 8, 8] # Number of modes along the 1st and 2nd dimension after each block\n",
    "list_M3 = [8, 8, 8, 8] # Number of modes along the 3rd dimension after each block\n",
    "model_name = 'G-FNO'\n",
    "\n",
    "# build the model\n",
    "model = model = GFNO_3D(num_channels, T_out, list_D, list_D3, list_M, list_M3, width=dv, padding=0, \n",
    "                        initial_step=1, reflection=False, grid_type='cartesian')\n",
    "\n",
    "# load the weights from the trained model\n",
    "epochs = 182\n",
    "name_config = f'GFNO3D-dv{dv}-S{S_in}-T{T_out}-padding0-learningrate0p0001-L1loss1p0-L2loss0p0-Ntrain27000-batchsize16'\\\n",
    "'-modes8-modestime8'\n",
    "model.load_state_dict(torch.load(f'./models/logs/models/bestmodel-{name_config}-epochs{epochs}.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491fa9b-389a-4fd6-9715-b98b95b50797",
   "metadata": {},
   "source": [
    "###Â F-FNO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca58743-b216-43bc-9d91-7d5fb7e49215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlayers = 28 # Number of layers\n",
    "dv = 16 # Number of channels after the uplift\n",
    "list_dv = [16]*nlayers # Number of channels after each block\n",
    "list_D1 = [32]*nlayers # Dimensions along the 1st dimension after each block\n",
    "list_D2 = [32]*nlayers # Dimensions along the 2nd dimension after each block\n",
    "list_D3 = [32]*(nlayers-4) + [64, 128, 256, 320] # Dimensions along the 3rd dimension after each block\n",
    "list_M1 = [16]*nlayers # Number of modes along the first dimension after each block\n",
    "list_M2 = [16]*nlayers # Number of modes along the first dimension after each block\n",
    "list_M3 = [16]*(nlayers-4) + [16, 32, 32, 32] # Number of modes along the first dimension after each block\n",
    "model_name = 'F-FNO'\n",
    "\n",
    "# build the model\n",
    "model = FFNO_3D(list_D1, list_D2, list_D3,\n",
    "                list_M1, list_M2, list_M3, dv, \n",
    "                input_dim=4, # to define the uplift network (last dimension after grid concatenation)\n",
    "                output_dim=1, # to define the projection network (last dimension after projection)\n",
    "                n_layers=nlayers, padding = 0)\n",
    "\n",
    "# load the weights from the trained model\n",
    "epochs = 350\n",
    "name_config = f'FFNO3D-dv{dv}-{nlayers}layers-S{S_in}-T{T_out}-padding0-learningrate0p0006-L1loss1p0-L2loss0p0'\\\n",
    "'-Ntrain27000-batchsize16'\n",
    "model.load_state_dict(torch.load(f'./models/logs/models/bestmodel-{name_config}-epochs{epochs}.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b9a2d-8c7f-42bc-8bab-c9e2d9d6bb83",
   "metadata": {},
   "source": [
    "# Intensity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c13654-028d-4baf-9af3-990ee33b809d",
   "metadata": {},
   "source": [
    "Compute the outputs for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f83e7c0-2211-48a8-ba0c-f6e2f70c259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "all_uE = np.zeros((Nval, S_out, S_out, T_out), dtype=np.float32)\n",
    "all_outE = np.zeros((Nval, S_out, S_out, T_out), dtype=np.float32)\n",
    "\n",
    "all_uZ = np.zeros((Nval, S_out, S_out, T_out), dtype=np.float32)\n",
    "all_outZ = np.zeros((Nval, S_out, S_out, T_out), dtype=np.float32)\n",
    "\n",
    "all_uN = np.zeros((Nval, S_out, S_out, T_out), dtype=np.float32)\n",
    "all_outN = np.zeros((Nval, S_out, S_out, T_out), dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "with torch.no_grad():        \n",
    "    for _ in val_loader:\n",
    "        a = _[0].to(device)\n",
    "        uE = _[1].to(device)\n",
    "        uZ = _[2].to(device)\n",
    "        uN = _[3].to(device)\n",
    "\n",
    "        outE, outZ, outN = model(a)\n",
    "        all_uE[i:i+a.shape[0]] = uE.cpu().numpy()[:, :, :, :, 0]\n",
    "        all_outE[i:i+a.shape[0]] = outE.cpu().numpy()[:, :, :, :, 0]\n",
    "        all_uZ[i:i+a.shape[0]] = uZ.cpu().numpy()[:, :, :, :, 0]\n",
    "        all_outZ[i:i+a.shape[0]] = outZ.cpu().numpy()[:, :, :, :, 0]\n",
    "        all_uN[i:i+a.shape[0]] = uN.cpu().numpy()[:, :, :, :, 0]\n",
    "        all_outN[i:i+a.shape[0]] = outN.cpu().numpy()[:, :, :, :, 0]\n",
    "        i += a.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ed213-c849-4906-9dd9-c08da6869056",
   "metadata": {},
   "source": [
    "Compute intensity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "845d032f-8322-4cf5-9cbc-702cfd0bfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = all_uE.shape[1] # number of sensors in the horizontal direction\n",
    "Ny = all_uE.shape[2] # number of sensors in the vertical direction\n",
    "Nt = all_uE.shape[3] # number of time steps\n",
    "\n",
    "all_rRMSE = dict()\n",
    "all_rRSD = dict()\n",
    "all_rCAV = dict()\n",
    "all_rPGV = dict()\n",
    "all_rFFTlow = dict()\n",
    "all_rFFTmid = dict()\n",
    "all_rFFThigh = dict()\n",
    "\n",
    "for c in ['E', 'N', 'Z']: # iterate over all components\n",
    "    if c=='E':\n",
    "        u = all_uE.copy()\n",
    "        out = all_outE.copy()\n",
    "\n",
    "    elif c=='N':\n",
    "        u = all_uN.copy()\n",
    "        out = all_outN.copy()\n",
    "\n",
    "    elif c=='Z':\n",
    "        u = all_uZ.copy()\n",
    "        out = all_outZ.copy()\n",
    "        \n",
    "    ### MEAN ERROR\n",
    "    eps = 1e-4\n",
    "    all_rRMSE[c] = np.sqrt(np.mean((u - out)**2/(u**2 + eps), axis=(1,2,3)))\n",
    "\n",
    "    u = u.reshape(Nval*Nx*Ny, Nt)\n",
    "    out = out.reshape(Nval*Nx*Ny, Nt)\n",
    "\n",
    "    ### RELATIVE SIGNIFICANT DURATION\n",
    "    Aint_u = Arias_integral(u, dt=dt)\n",
    "    Aint_out = Arias_integral(out, dt=dt)\n",
    "\n",
    "    RSD_u = relative_significant_duration(Aint_u, dt=dt)\n",
    "    RSD_out = relative_significant_duration(Aint_out, dt=dt)\n",
    "\n",
    "    all_rRSD[c] = score_metric(RSD_u, RSD_out, method='bias') # one score per sample and per sensor\n",
    "\n",
    "    ### CUMULATIVE ABSOLUTE VELOCITY\n",
    "    CAV_u = cumulative_absolute_velocity(u, dt=dt)\n",
    "    CAV_out = cumulative_absolute_velocity(out, dt=dt)\n",
    "    all_rCAV[c] = score_metric(CAV_u, CAV_out, method='bias')\n",
    "\n",
    "    ### PEAK GROUND VELOCITY\n",
    "    PGV_u = np.max(np.abs(u), axis=1)\n",
    "    PGV_out = np.max(np.abs(out), axis=1)\n",
    "    all_rPGV[c] = score_metric(PGV_u, PGV_out, method='bias')\n",
    "\n",
    "    ### FOURIER SPECTRA\n",
    "    low_freq_u, mid_freq_u, high_freq_u = fourier_spectra(u, (0.1, 0.5), (0.75, 1.5), (2.5, 3.5), dt=dt)\n",
    "    low_freq_out, mid_freq_out, high_freq_out = fourier_spectra(out, (0.1, 0.5), (0.75, 1.5), (2.5, 3.5), dt=dt)\n",
    "\n",
    "    all_rFFTlow[c] = score_metric(low_freq_u, low_freq_out, method='bias')\n",
    "    all_rFFTmid[c] = score_metric(mid_freq_u, mid_freq_out, method='bias')\n",
    "    all_rFFThigh[c] = score_metric(high_freq_u, high_freq_out, method='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2b998-341d-429e-8533-d8a8cf728ba1",
   "metadata": {},
   "source": [
    "Compute the mean of the three components and print the mean and standard deviation of all samples and all spatial points (note that we are considering only 5 validation samples here, explaining why the results are different from the paper). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62cb643-b8d7-42cf-bb67-0e0aab06a08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rRMSE: mean=0.169 - std=0.058\n",
      "rRSD: mean=-0.169 - std=0.357\n",
      "rCAV: mean=-0.425 - std=0.159\n",
      "rPGV: mean=-0.136 - std=0.168\n",
      "rFFTlow: mean=-0.006 - std=0.315\n",
      "rFFTmid: mean=-0.106 - std=0.390\n",
      "rFFThigh: mean=-0.091 - std=0.638\n"
     ]
    }
   ],
   "source": [
    "for key, metric in zip(['rRMSE', 'rRSD', 'rCAV', 'rPGV', 'rFFTlow', 'rFFTmid', 'rFFThigh'],\n",
    "                       [all_rRMSE, all_rRSD, all_rCAV, all_rPGV, all_rFFTlow, all_rFFTmid, all_rFFThigh]):\n",
    "    mean_metric = (metric['E'] + metric['N'] + metric['Z'])/3\n",
    "    print(f\"{key}: mean={np.mean(mean_metric):.3f} - std={np.std(mean_metric):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676e199-633a-44cf-8276-00094c8d7ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
